import os
import numpy as np
import torch

def world2image(traj_w, H_inv):
    # Converts points from Euclidean to homogeneous space, by (x, y) â†’ (x, y, 1)
    a = np.ones((traj_w.shape[0], 1))
    traj_homog = np.hstack((traj_w, np.ones((traj_w.shape[0], 1)))).T
    # to camera frame
    traj_cam = np.matmul(H_inv, traj_homog)
    # to pixel coords
    traj_uvz = np.transpose(traj_cam/traj_cam[2])
    return traj_uvz[:, :2].astype(int)

H = np.loadtxt("h.txt")
H_inv = np.linalg.inv(H)
traj = torch.tensor([[[10.2734,  4.1014],
         [10.7832,  5.5584],
         [10.6207,  4.9620],
         [ 6.6120,  3.5534],
         [ 5.3967,  4.2680],
         [12.0487,  5.9873],
         [12.0773,  5.1846],
         [ 1.3579,  2.9295]],

        [[ 9.9645,  4.1522],
         [10.5382,  5.6118],
         [10.3839,  4.9543],
         [ 7.0716,  3.4844],
         [ 5.8469,  4.0956],
         [11.7501,  5.9025],
         [11.7705,  4.9942],
         [ 1.3988,  2.9391]],

        [[ 9.6555,  4.2030],
         [10.2934,  5.6655],
         [10.1472,  4.9469],
         [ 7.5452,  3.4785],
         [ 6.2969,  3.9233],
         [11.4514,  5.8178],
         [11.4880,  4.7932],
         [ 1.4474,  2.9575]],

        [[ 9.3465,  4.2536],
         [10.0487,  5.7190],
         [ 9.9104,  4.9450],
         [ 8.0187,  3.4725],
         [ 6.7471,  3.7510],
         [11.1582,  5.6999],
         [11.2056,  4.5923],
         [ 1.4960,  2.9758]],

        [[ 9.0374,  4.3045],
         [ 9.8039,  5.7727],
         [ 9.6740,  4.9937],
         [ 8.4923,  3.4665],
         [ 7.0813,  3.6135],
         [10.8705,  5.5488],
         [10.9231,  4.3913],
         [ 1.5444,  2.9942]],

        [[ 8.7768,  4.3780],
         [ 9.5741,  5.8185],
         [ 9.4379,  5.0426],
         [ 8.9658,  3.4606],
         [ 7.3656,  3.4909],
         [10.5828,  5.3978],
         [10.6601,  4.2890],
         [ 1.5930,  3.0126]],

        [[ 8.5371,  4.4613],
         [ 9.3594,  5.8567],
         [ 9.2015,  5.0913],
         [ 9.4192,  3.4789],
         [ 7.6502,  3.3684],
         [10.3014,  5.2166],
         [10.3970,  4.1868],
         [ 1.6416,  3.0310]],

        [[ 8.2972,  4.5446],
         [ 9.1447,  5.8949],
         [ 8.9654,  5.1400],
         [ 9.8725,  3.4973],
         [ 7.9345,  3.2458],
         [10.0261,  5.0054],
         [10.1234,  4.0906],
         [ 1.6902,  3.0494]],

        [[ 8.0574,  4.6279],
         [ 8.9300,  5.9331],
         [ 8.7311,  5.1982],
         [10.3258,  3.5157],
         [ 8.2473,  3.1684],
         [ 9.7511,  4.7942],
         [ 9.8077,  4.0190],
         [ 1.9636,  3.0775]],

        [[ 7.8348,  4.6985],
         [ 8.7154,  5.9713],
         [ 8.5045,  5.2947],
         [10.7804,  3.5460],
         [ 8.5602,  3.0909],
         [ 9.4543,  4.7901],
         [ 9.4920,  3.9474],
         [ 2.3332,  3.1097]],

        [[ 7.6380,  4.7503],
         [ 8.5028,  6.0717],
         [ 8.2778,  5.3908],
         [11.2481,  3.6840],
         [ 8.8730,  3.0136],
         [ 9.1552,  4.8090],
         [ 9.1681,  3.8928],
         [ 2.7030,  3.1420]],

        [[ 7.4414,  4.8023],
         [ 8.2923,  6.2345],
         [ 8.0511,  5.4873],
         [11.7160,  3.8217],
         [ 9.2314,  2.9470],
         [ 8.8562,  4.8278],
         [ 8.8115,  3.9061],
         [ 3.0728,  3.1742]]])

converted_traj = []
for tra in traj:
    a = world2image(tra, H_inv)
    converted_traj.append(a)

b = np.asarray(converted_traj)
print(b)
for a in range(8):
    lst2 = [item[a] for item in b]
    lt = np.asarray(lst2)
    print(lt[:, 0])
    print(lt[:, 1])